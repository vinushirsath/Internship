{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce8244c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets import all necessary libraries\n",
    "import selenium\n",
    "from selenium import webdriver    #Importing web driver module from selenium to open automated chrome window.\n",
    "import pandas as pd               #importing pands to make dataframe\n",
    "from selenium.webdriver.common.by import By     #importing inbuild class by\n",
    "import warnings\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from PIL import Image\n",
    "import requests\n",
    "import re\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f667015",
   "metadata": {},
   "source": [
    "# 1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bce7519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\hp\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#Lets maximize web driver\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "512cd286",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the url\n",
    "\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "546e2b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping of Ranks\n",
    "Ranks=[]\n",
    "ranks=driver.find_elements(By.XPATH, \"//td[1][@align='center']\")\n",
    "for i in ranks:\n",
    "    try:\n",
    "        \n",
    "    \n",
    "        Ranks.append(i.text.replace(\".\",\"\"))\n",
    "    except NoSuchElementException:\n",
    "        \n",
    "        Ranks.append(\"-\")\n",
    "        \n",
    "len(Ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "021f4a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Baby Shark Dance\"[4]',\n",
       " '\"Despacito\"[7]',\n",
       " '\"Johny Johny Yes Papa\"[14]',\n",
       " '\"Shape of You\"[15]',\n",
       " '\"Bath Song\"[17]',\n",
       " '\"See You Again\"[18]',\n",
       " '\"Phonics Song with Two Words\"[23]',\n",
       " '\"Uptown Funk\"[24]',\n",
       " '\"Learning Colors – Colorful Eggs on a Farm\"[25]',\n",
       " '\"Wheels on the Bus\"[26]',\n",
       " '\"Gangnam Style\"[27]',\n",
       " '\"Masha and the Bear – Recipe for Disaster\"[32]',\n",
       " '\"Dame Tu Cosita\"[33]',\n",
       " '\"Sugar\"[34]',\n",
       " '\"Roar\"[35]',\n",
       " '\"Counting Stars\"[36]',\n",
       " '\"Axel F\"[37]',\n",
       " '\"Sorry\"[38]',\n",
       " '\"Thinking Out Loud\"[39]',\n",
       " '\"Baa Baa Black Sheep\"[40]',\n",
       " '\"Dark Horse\"[41]',\n",
       " '\"Faded\"[42]',\n",
       " '\"Girls Like You\"[43]',\n",
       " '\"Let Her Go\"[44]',\n",
       " '\"Waka Waka (This Time for Africa)\"[45]',\n",
       " '\"Perfect\"[46]',\n",
       " '\"Bailando\"[47]',\n",
       " '\"Lean On\"[48]',\n",
       " '\"Humpty the train on a fruits ride\"[49]',\n",
       " '\"Shake It Off\"[50]']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping of Ranks\n",
    "Name=[]\n",
    "name=driver.find_elements(By.XPATH, \"//*[@id='mw-content-text']/div[1]/table[2]/tbody/tr[*]/td[2]\")\n",
    "for i in name:\n",
    "    try:\n",
    "        \n",
    "    \n",
    "        Name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        \n",
    "        Name.append(\"-\")\n",
    "        \n",
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f426e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Pinkfong Baby Shark - Kids' Songs & Stories\",\n",
       " 'Luis Fonsi',\n",
       " 'LooLoo Kids',\n",
       " 'Ed Sheeran',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Wiz Khalifa',\n",
       " 'ChuChu TV',\n",
       " 'Mark Ronson',\n",
       " 'Miroshka TV',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Psy',\n",
       " 'Get Movies',\n",
       " 'El Chombo',\n",
       " 'Maroon 5',\n",
       " 'Katy Perry',\n",
       " 'OneRepublic',\n",
       " 'Crazy Frog',\n",
       " 'Justin Bieber',\n",
       " 'Ed Sheeran',\n",
       " 'Cocomelon – Nursery Rhymes',\n",
       " 'Katy Perry',\n",
       " 'Alan Walker',\n",
       " 'Maroon 5',\n",
       " 'Passenger',\n",
       " 'Shakira',\n",
       " 'Ed Sheeran',\n",
       " 'Enrique Iglesias',\n",
       " 'Major Lazer',\n",
       " 'Kiddiestv Hindi – Nursery Rhymes & Kids Songs',\n",
       " 'Taylor Swift']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping of Artist\n",
    "Artist=[]\n",
    "art=driver.find_elements(By.XPATH, \"//*[@id='mw-content-text']/div[1]/table[2]/tbody/tr[*]/td[3]\")\n",
    "for i in art:\n",
    "    try:\n",
    "        \n",
    "    \n",
    "        Artist.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        \n",
    "        Artist.append(\"-\")\n",
    "        \n",
    "Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f6b6177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['June 17, 2016',\n",
       " 'January 12, 2017',\n",
       " 'October 8, 2016',\n",
       " 'January 30, 2017',\n",
       " 'May 2, 2018',\n",
       " 'April 6, 2015',\n",
       " 'March 6, 2014',\n",
       " 'November 19, 2014',\n",
       " 'February 27, 2018',\n",
       " 'May 24, 2018',\n",
       " 'July 15, 2012',\n",
       " 'January 31, 2012',\n",
       " 'April 5, 2018',\n",
       " 'January 14, 2015',\n",
       " 'September 5, 2013',\n",
       " 'May 31, 2013',\n",
       " 'June 16, 2009',\n",
       " 'October 22, 2015',\n",
       " 'October 7, 2014',\n",
       " 'June 25, 2018',\n",
       " 'February 20, 2014',\n",
       " 'December 3, 2015',\n",
       " 'May 31, 2018',\n",
       " 'July 25, 2012',\n",
       " 'June 4, 2010',\n",
       " 'November 9, 2017',\n",
       " 'April 11, 2014',\n",
       " 'March 22, 2015',\n",
       " 'January 26, 2018',\n",
       " 'August 18, 2014']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping of Upload Date\n",
    "Upload_date=[]\n",
    "ud=driver.find_elements(By.XPATH, \"//*[@id='mw-content-text']/div[1]/table[2]/tbody/tr[*]/td[5]\")\n",
    "for i in ud:\n",
    "    try:\n",
    "        \n",
    "    \n",
    "        Upload_date.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        \n",
    "        Upload_date.append(\"-\")\n",
    "        \n",
    "Upload_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91eb8926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11.83',\n",
       " '8.02',\n",
       " '6.54',\n",
       " '5.86',\n",
       " '5.81',\n",
       " '5.71',\n",
       " '5.04',\n",
       " '4.77',\n",
       " '4.74',\n",
       " '4.69',\n",
       " '4.62',\n",
       " '4.52',\n",
       " '4.15',\n",
       " '3.79',\n",
       " '3.69',\n",
       " '3.69',\n",
       " '3.63',\n",
       " '3.61',\n",
       " '3.52',\n",
       " '3.44',\n",
       " '3.40',\n",
       " '3.38',\n",
       " '3.35',\n",
       " '3.35',\n",
       " '3.34',\n",
       " '3.31',\n",
       " '3.30',\n",
       " '3.29',\n",
       " '3.24',\n",
       " '3.23']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping of Views\n",
    "Views=[]\n",
    "v=driver.find_elements(By.XPATH, \"//*[@id='mw-content-text']/div[1]/table[2]/tbody/tr[*]/td[4]\")\n",
    "for i in v:\n",
    "    try:\n",
    "        \n",
    "    \n",
    "        Views.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        \n",
    "        Views.append(\"-\")\n",
    "        \n",
    "Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74a0fa94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views in Billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>11.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[14]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Shape of You\"[15]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"Bath Song\"[17]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Phonics Song with Two Words\"[23]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>\"Uptown Funk\"[24]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[25]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>\"Wheels on the Bus\"[26]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>\"Gangnam Style\"[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[32]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>\"Dame Tu Cosita\"[33]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>\"Sugar\"[34]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>\"Roar\"[35]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>\"Counting Stars\"[36]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>\"Thinking Out Loud\"[39]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[40]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>\"Dark Horse\"[41]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>\"Faded\"[42]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>\"Girls Like You\"[43]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>\"Let Her Go\"[44]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[45]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>\"Perfect\"[46]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>\"Bailando\"[47]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>\"Lean On\"[48]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[49]</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>\"Shake It Off\"[50]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0     1                            \"Baby Shark Dance\"[4]   \n",
       "1     2                                   \"Despacito\"[7]   \n",
       "2     3                       \"Johny Johny Yes Papa\"[14]   \n",
       "3     4                               \"Shape of You\"[15]   \n",
       "4     5                                  \"Bath Song\"[17]   \n",
       "5     6                              \"See You Again\"[18]   \n",
       "6     7                \"Phonics Song with Two Words\"[23]   \n",
       "7     8                                \"Uptown Funk\"[24]   \n",
       "8     9  \"Learning Colors – Colorful Eggs on a Farm\"[25]   \n",
       "9    10                          \"Wheels on the Bus\"[26]   \n",
       "10   11                              \"Gangnam Style\"[27]   \n",
       "11   12   \"Masha and the Bear – Recipe for Disaster\"[32]   \n",
       "12   13                             \"Dame Tu Cosita\"[33]   \n",
       "13   14                                      \"Sugar\"[34]   \n",
       "14   15                                       \"Roar\"[35]   \n",
       "15   16                             \"Counting Stars\"[36]   \n",
       "16   17                                     \"Axel F\"[37]   \n",
       "17   18                                      \"Sorry\"[38]   \n",
       "18   19                          \"Thinking Out Loud\"[39]   \n",
       "19   20                        \"Baa Baa Black Sheep\"[40]   \n",
       "20   21                                 \"Dark Horse\"[41]   \n",
       "21   22                                      \"Faded\"[42]   \n",
       "22   23                             \"Girls Like You\"[43]   \n",
       "23   24                                 \"Let Her Go\"[44]   \n",
       "24   25           \"Waka Waka (This Time for Africa)\"[45]   \n",
       "25   26                                    \"Perfect\"[46]   \n",
       "26   27                                   \"Bailando\"[47]   \n",
       "27   28                                    \"Lean On\"[48]   \n",
       "28   29          \"Humpty the train on a fruits ride\"[49]   \n",
       "29   30                               \"Shake It Off\"[50]   \n",
       "\n",
       "                                           Artist        Upload Date  \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                      Luis Fonsi   January 12, 2017   \n",
       "2                                     LooLoo Kids    October 8, 2016   \n",
       "3                                      Ed Sheeran   January 30, 2017   \n",
       "4                      Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "5                                     Wiz Khalifa      April 6, 2015   \n",
       "6                                       ChuChu TV      March 6, 2014   \n",
       "7                                     Mark Ronson  November 19, 2014   \n",
       "8                                     Miroshka TV  February 27, 2018   \n",
       "9                      Cocomelon – Nursery Rhymes       May 24, 2018   \n",
       "10                                            Psy      July 15, 2012   \n",
       "11                                     Get Movies   January 31, 2012   \n",
       "12                                      El Chombo      April 5, 2018   \n",
       "13                                       Maroon 5   January 14, 2015   \n",
       "14                                     Katy Perry  September 5, 2013   \n",
       "15                                    OneRepublic       May 31, 2013   \n",
       "16                                     Crazy Frog      June 16, 2009   \n",
       "17                                  Justin Bieber   October 22, 2015   \n",
       "18                                     Ed Sheeran    October 7, 2014   \n",
       "19                     Cocomelon – Nursery Rhymes      June 25, 2018   \n",
       "20                                     Katy Perry  February 20, 2014   \n",
       "21                                    Alan Walker   December 3, 2015   \n",
       "22                                       Maroon 5       May 31, 2018   \n",
       "23                                      Passenger      July 25, 2012   \n",
       "24                                        Shakira       June 4, 2010   \n",
       "25                                     Ed Sheeran   November 9, 2017   \n",
       "26                               Enrique Iglesias     April 11, 2014   \n",
       "27                                    Major Lazer     March 22, 2015   \n",
       "28  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "29                                   Taylor Swift    August 18, 2014   \n",
       "\n",
       "   Views in Billion  \n",
       "0             11.83  \n",
       "1              8.02  \n",
       "2              6.54  \n",
       "3              5.86  \n",
       "4              5.81  \n",
       "5              5.71  \n",
       "6              5.04  \n",
       "7              4.77  \n",
       "8              4.74  \n",
       "9              4.69  \n",
       "10             4.62  \n",
       "11             4.52  \n",
       "12             4.15  \n",
       "13             3.79  \n",
       "14             3.69  \n",
       "15             3.69  \n",
       "16             3.63  \n",
       "17             3.61  \n",
       "18             3.52  \n",
       "19             3.44  \n",
       "20             3.40  \n",
       "21             3.38  \n",
       "22             3.35  \n",
       "23             3.35  \n",
       "24             3.34  \n",
       "25             3.31  \n",
       "26             3.30  \n",
       "27             3.29  \n",
       "28             3.24  \n",
       "29             3.23  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making Dataframe\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df[\"Rank\"]=Ranks\n",
    "df[\"Name\"]=Name\n",
    "df[\"Artist\"]=Artist\n",
    "df[\"Upload Date\"]=Upload_date\n",
    "df[\"Views in Billion\"]=Views\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0a0f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4348265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "769d635e",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9bce8f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\hp\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#Lets maximize web driver\n",
    "driver.maximize_window()\n",
    "\n",
    "#Opening the url\n",
    "\n",
    "driver.get(\"https://www.bcci.tv/\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1b275b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "Title=[]\n",
    "\n",
    "title=driver.find_elements(By.XPATH,\"//span[@class='matchOrderText ng-binding ng-scope']\")\n",
    "for i in title[0:8]:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        Title.append(i.text.replace(\"-\",\"\"))\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Title.append(\"-\")\n",
    "        \n",
    "len(Title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "56b9e61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "Series=[]\n",
    "\n",
    "series=driver.find_elements(By.XPATH,\"//span[@class='ng-binding']\")\n",
    "for i in series[0:8]:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        Series.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Series.append(\"-\")\n",
    "        \n",
    "len(Series)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e9430e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Place=[]\n",
    "\n",
    "place=driver.find_elements(By.XPATH,\"//span[@class='ng-binding']\")\n",
    "for i in place[0:8]:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        Place.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Place.append(\"-\")\n",
    "        \n",
    "len(Place)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "acf6cf7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "Date=[]\n",
    "\n",
    "date=driver.find_elements(By.XPATH,\"//h5[@class='ng-binding']\")\n",
    "for i in date[0:8]:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        Date.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Date.append(\"-\")\n",
    "        \n",
    "len(Date)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "54cd47e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "Time=[]\n",
    "\n",
    "time=driver.find_elements(By.XPATH,\"//h5[@class='text-right ng-binding']\")\n",
    "for i in time:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        Time.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Time.append(\"-\")\n",
    "        \n",
    "len(Time)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "117a8441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Series</th>\n",
       "      <th>Title</th>\n",
       "      <th>Place</th>\n",
       "      <th>Time</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA A IN BANGLADESH MULTI DAY SERIES</td>\n",
       "      <td>FirstClass Match</td>\n",
       "      <td>INDIA A IN BANGLADESH MULTI DAY SERIES</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "      <td>6 DEC 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stumps Day 2</td>\n",
       "      <td>1st T20I</td>\n",
       "      <td>Stumps Day 2</td>\n",
       "      <td>11:30 AM IST</td>\n",
       "      <td>9 DEC 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "      <td>10 DEC 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INDIA TOUR OF BANGLADESH ODI SERIES 2022-23</td>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>INDIA TOUR OF BANGLADESH ODI SERIES 2022-23</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "      <td>11 DEC 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>1st Test</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "      <td>14 DEC 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INDIA TOUR OF BANGLADESH TEST SERIES 2022-23</td>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>INDIA TOUR OF BANGLADESH TEST SERIES 2022-23</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "      <td>14 DEC 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>4th T20I</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "      <td>17 DEC 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>5th T20I</td>\n",
       "      <td>AUSTRALIA WOMEN TOUR OF INDIA 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "      <td>20 DEC 2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Series              Title  \\\n",
       "0        INDIA A IN BANGLADESH MULTI DAY SERIES  FirstClass Match    \n",
       "1                                  Stumps Day 2          1st T20I    \n",
       "2            AUSTRALIA WOMEN TOUR OF INDIA 2022           3rd ODI    \n",
       "3   INDIA TOUR OF BANGLADESH ODI SERIES 2022-23          2nd T20I    \n",
       "4            AUSTRALIA WOMEN TOUR OF INDIA 2022          1st Test    \n",
       "5  INDIA TOUR OF BANGLADESH TEST SERIES 2022-23          3rd T20I    \n",
       "6            AUSTRALIA WOMEN TOUR OF INDIA 2022          4th T20I    \n",
       "7            AUSTRALIA WOMEN TOUR OF INDIA 2022          5th T20I    \n",
       "\n",
       "                                          Place          Time         Date  \n",
       "0        INDIA A IN BANGLADESH MULTI DAY SERIES   7:00 PM IST   6 DEC 2022  \n",
       "1                                  Stumps Day 2  11:30 AM IST   9 DEC 2022  \n",
       "2            AUSTRALIA WOMEN TOUR OF INDIA 2022   7:00 PM IST  10 DEC 2022  \n",
       "3   INDIA TOUR OF BANGLADESH ODI SERIES 2022-23   9:30 AM IST  11 DEC 2022  \n",
       "4            AUSTRALIA WOMEN TOUR OF INDIA 2022   7:00 PM IST  14 DEC 2022  \n",
       "5  INDIA TOUR OF BANGLADESH TEST SERIES 2022-23   7:00 PM IST  14 DEC 2022  \n",
       "6            AUSTRALIA WOMEN TOUR OF INDIA 2022   7:00 PM IST  17 DEC 2022  \n",
       "7            AUSTRALIA WOMEN TOUR OF INDIA 2022   9:30 AM IST  20 DEC 2022  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame()\n",
    "df[\"Series\"]=Series\n",
    "df[\"Title\"]=Title\n",
    "df[\"Place\"]=Place\n",
    "df[\"Time\"]=Time\n",
    "df[\"Date\"]=Date\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3f8897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "098e8b3e",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of selenium exception from guru99.com. Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00c7649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\hp\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#Lets maximize web driver\n",
    "driver.maximize_window()\n",
    "\n",
    "#Opening the url\n",
    "\n",
    "driver.get(\"https://www.guru99.com/\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "836daf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Selenium=driver.find_element(By.XPATH, \"//input[@class='gsc-input']\")\n",
    "Selenium.send_keys(\"Selenium Exception handling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "354ccf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search button\n",
    "search_btn=driver.find_element(By.XPATH,\"//button[@class='gsc-search-button gsc-search-button-v2']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00507ada",
   "metadata": {},
   "source": [
    "-Cant understand the problem statement. Which name & description you want?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a461431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scrapping of Name\n",
    "Name=[]\n",
    "n=driver.find_elements(By.XPATH, \"/html/body/div/section/div/div/div[1]/div[1]/div/h3[*]\")\n",
    "for i in n:\n",
    "    try:\n",
    "        \n",
    "    \n",
    "        Name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        \n",
    "        Name.append(\"-\")\n",
    "        \n",
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f73b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b18da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d7bbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6758d65c",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4cea9d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\hp\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#Lets maximize web driver\n",
    "driver.maximize_window()\n",
    "\n",
    "#Opening the url\n",
    "\n",
    "driver.get(\"http://statisticstimes.com/\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "145bb59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Economy=driver.find_element(By.XPATH, \"/html/body/div[2]/div[1]/div[2]/div[2]/button\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bad38722",
   "metadata": {},
   "outputs": [],
   "source": [
    "India=driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "587bb14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "Rank=[]\n",
    "\n",
    "rank=driver.find_elements(By.XPATH,\"//td[@class='data1']\")\n",
    "for i in rank[0:33]:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        Rank.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Rank.append(\"-\")\n",
    "        \n",
    "len(Rank)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "be7bdffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "State=[]\n",
    "\n",
    "state=driver.find_elements(By.XPATH,\"//td[@class='name']\")\n",
    "for i in state[0:33]:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        State.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        State.append(\"-\")\n",
    "        \n",
    "len(State)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "af904aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GSDP(18-19)- at current prices\n",
    "\n",
    "GSDP_18_19=[]\n",
    "\n",
    "gsdp=driver.find_elements(By.XPATH,\"//td[@class='data sorting_1']\")\n",
    "for i in gsdp[0:33]:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        GSDP_18_19.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        GSDP_18_19.append(\"-\")\n",
    "        \n",
    "len(GSDP_18_19)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "db4ddb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GSDP(19_20)- at current prices\n",
    "\n",
    "GSDP_19_20=[]\n",
    "\n",
    "gsdp1=driver.find_elements(By.XPATH,\"//td[3][@class='data']\")\n",
    "for i in gsdp1[0:33]:\n",
    "        \n",
    "    try:\n",
    "        \n",
    "        GSDP_19_20.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        GSDP_19_20.append(\"-\")\n",
    "        \n",
    "len(GSDP_19_20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "126d2458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "share_18_19=[]\n",
    "sh=driver.find_elements(By.XPATH,\"//td[5][@class='data']\")\n",
    "for i in sh[0:33]:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        share_18_19.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        share_18_19.append(\"-\")\n",
    "        \n",
    "len(share_18_19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3d558cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDP=[]\n",
    "gdp=driver.find_elements(By.XPATH,\"//td[6][@class='data']\")\n",
    "for i in gdp[0:33]:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        GDP.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        GDP.append(\"-\")\n",
    "        \n",
    "len(GDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9815cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making DataFrame\n",
    "df=pd.DataFrame()\n",
    "df[\"Rank\"]=Rank\n",
    "df[\"State\"]=State\n",
    "df[\"GSDP (18-19)- at current prices\"]=GSDP_18_19\n",
    "df[\"GSDP (19-20)- at current prices\"]=GSDP_19_20\n",
    "df[\"Share (18-19)\"]=share_18_19\n",
    "df[\"GDP($ Dollar)\"]=GDP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e7b3cdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP (18-19)- at current prices</th>\n",
       "      <th>GSDP (19-20)- at current prices</th>\n",
       "      <th>Share (18-19)</th>\n",
       "      <th>GDP($ Dollar)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP (18-19)- at current prices  \\\n",
       "0     1                Maharashtra                       2,632,792   \n",
       "1     2                 Tamil Nadu                       1,630,208   \n",
       "2     3              Uttar Pradesh                       1,584,764   \n",
       "3     4                    Gujarat                       1,502,899   \n",
       "4     5                  Karnataka                       1,493,127   \n",
       "5     6                West Bengal                       1,089,898   \n",
       "6     7                  Rajasthan                         942,586   \n",
       "7     8             Andhra Pradesh                         862,957   \n",
       "8     9                  Telangana                         861,031   \n",
       "9    10             Madhya Pradesh                         809,592   \n",
       "10   11                     Kerala                         781,653   \n",
       "11   12                      Delhi                         774,870   \n",
       "12   13                    Haryana                         734,163   \n",
       "13   14                      Bihar                         530,363   \n",
       "14   15                     Punjab                         526,376   \n",
       "15   16                     Odisha                         487,805   \n",
       "16   17                      Assam                         315,881   \n",
       "17   18               Chhattisgarh                         304,063   \n",
       "18   19                  Jharkhand                         297,204   \n",
       "19   20                Uttarakhand                         245,895   \n",
       "20   21            Jammu & Kashmir                         155,956   \n",
       "21   22           Himachal Pradesh                         153,845   \n",
       "22   23                        Goa                          73,170   \n",
       "23   24                    Tripura                          49,845   \n",
       "24   25                 Chandigarh                          42,114   \n",
       "25   26                 Puducherry                          34,433   \n",
       "26   27                  Meghalaya                          33,481   \n",
       "27   28                     Sikkim                          28,723   \n",
       "28   29                    Manipur                          27,870   \n",
       "29   30                   Nagaland                          27,283   \n",
       "30   31          Arunachal Pradesh                          24,603   \n",
       "31   32                    Mizoram                          22,287   \n",
       "32   33  Andaman & Nicobar Islands                               -   \n",
       "\n",
       "   GSDP (19-20)- at current prices Share (18-19) GDP($ Dollar)  \n",
       "0                                -        13.94%       399.921  \n",
       "1                        1,845,853         8.63%       247.629  \n",
       "2                        1,687,818         8.39%       240.726  \n",
       "3                                -         7.96%       228.290  \n",
       "4                        1,631,977         7.91%       226.806  \n",
       "5                        1,253,832         5.77%       165.556  \n",
       "6                        1,020,989         4.99%       143.179  \n",
       "7                          972,782         4.57%       131.083  \n",
       "8                          969,604         4.56%       130.791  \n",
       "9                          906,672         4.29%       122.977  \n",
       "10                               -         4.14%       118.733  \n",
       "11                         856,112         4.10%       117.703  \n",
       "12                         831,610         3.89%       111.519  \n",
       "13                         611,804         2.81%        80.562  \n",
       "14                         574,760         2.79%        79.957  \n",
       "15                         521,275         2.58%        74.098  \n",
       "16                               -         1.67%        47.982  \n",
       "17                         329,180         1.61%        46.187  \n",
       "18                         328,598         1.57%        45.145  \n",
       "19                               -         1.30%        37.351  \n",
       "20                               -         0.83%        23.690  \n",
       "21                         165,472         0.81%        23.369  \n",
       "22                          80,449         0.39%        11.115  \n",
       "23                          55,984         0.26%         7.571  \n",
       "24                               -         0.22%         6.397  \n",
       "25                          38,253         0.18%         5.230  \n",
       "26                          36,572         0.18%         5.086  \n",
       "27                          32,496         0.15%         4.363  \n",
       "28                          31,790         0.15%         4.233  \n",
       "29                               -         0.14%         4.144  \n",
       "30                               -         0.13%         3.737  \n",
       "31                          26,503         0.12%         3.385  \n",
       "32                               -             -             -  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de3d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f0cf593",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of trending repositories on Github.com. Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7f07fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\hp\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#Lets maximize web driver\n",
    "driver.maximize_window()\n",
    "\n",
    "#Opening the url\n",
    "\n",
    "driver.get(\"https://github.com/\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1519ff67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Title=[]\n",
    "title=driver.find_elements(By.XPATH,\"//span[@class='text-normal']\")\n",
    "for i in title[0:15]:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        Title.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Title.append(\"-\")\n",
    "        \n",
    "len(Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "92d0f52d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "Descr=[]\n",
    "de=driver.find_elements(By.XPATH,\"//p[@class='col-9 color-fg-muted my-1 pr-4']\")\n",
    "for i in de[0:15]:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        Descr.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Descr.append(\"-\")\n",
    "        \n",
    "len(Descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9ae60d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "Count=[]\n",
    "ct=driver.find_elements(By.XPATH,\"//a[2][@class='Link--muted d-inline-block mr-3']\")\n",
    "for i in ct[0:15]:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        Count.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Count.append(\"-\")\n",
    "        \n",
    "len(Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "214a8089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "Language=[]\n",
    "ln=driver.find_elements(By.XPATH,\"//span[@class='d-inline-block ml-0 mr-3']\")\n",
    "for i in ln[0:15]:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        Language.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Language.append(\"-\")\n",
    "        \n",
    "len(Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e1d39bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fuergaosi233 /</td>\n",
       "      <td>Use ChatGPT On Wechat via wechaty</td>\n",
       "      <td>222</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ggerganov /</td>\n",
       "      <td>Port of OpenAI's Whisper model in C/C++</td>\n",
       "      <td>225</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>remix-run /</td>\n",
       "      <td>Declarative routing for React</td>\n",
       "      <td>9,671</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AutumnWhj /</td>\n",
       "      <td>ChatGPT for wechat</td>\n",
       "      <td>51</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paradigmxyz /</td>\n",
       "      <td>Modular, contributor-friendly and blazing-fast...</td>\n",
       "      <td>35</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>869413421 /</td>\n",
       "      <td>为个人微信接入ChatGPT</td>\n",
       "      <td>66</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rawandahmad698 /</td>\n",
       "      <td>⚡️ Python client for the unofficial ChatGPT AP...</td>\n",
       "      <td>112</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>surrealdb /</td>\n",
       "      <td>A scalable, distributed, collaborative, docume...</td>\n",
       "      <td>376</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gragland /</td>\n",
       "      <td>A ChatGPT Chrome extension. Integrates ChatGPT...</td>\n",
       "      <td>40</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tencent /</td>\n",
       "      <td>Hippy is designed to easily build cross-platfo...</td>\n",
       "      <td>857</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>acheong08 /</td>\n",
       "      <td>Lightweight package for interacting with ChatG...</td>\n",
       "      <td>464</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>izackwu /</td>\n",
       "      <td>TeachYourselfCS 的中文翻译 | A Chinese translation ...</td>\n",
       "      <td>3,015</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rmcelreath /</td>\n",
       "      <td>Statistical Rethinking Course for Jan-Mar 2023</td>\n",
       "      <td>9</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ryanmcdermott /</td>\n",
       "      <td>🛁 Clean Code concepts adapted for JavaScript</td>\n",
       "      <td>10,307</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>humanloop /</td>\n",
       "      <td>Curated list of awesome tools, demos, docs for...</td>\n",
       "      <td>16</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Repository title                             Repository description  \\\n",
       "0     fuergaosi233 /                  Use ChatGPT On Wechat via wechaty   \n",
       "1        ggerganov /            Port of OpenAI's Whisper model in C/C++   \n",
       "2        remix-run /                      Declarative routing for React   \n",
       "3        AutumnWhj /                                 ChatGPT for wechat   \n",
       "4      paradigmxyz /  Modular, contributor-friendly and blazing-fast...   \n",
       "5        869413421 /                                     为个人微信接入ChatGPT   \n",
       "6   rawandahmad698 /  ⚡️ Python client for the unofficial ChatGPT AP...   \n",
       "7        surrealdb /  A scalable, distributed, collaborative, docume...   \n",
       "8         gragland /  A ChatGPT Chrome extension. Integrates ChatGPT...   \n",
       "9          Tencent /  Hippy is designed to easily build cross-platfo...   \n",
       "10       acheong08 /  Lightweight package for interacting with ChatG...   \n",
       "11         izackwu /  TeachYourselfCS 的中文翻译 | A Chinese translation ...   \n",
       "12      rmcelreath /     Statistical Rethinking Course for Jan-Mar 2023   \n",
       "13   ryanmcdermott /       🛁 Clean Code concepts adapted for JavaScript   \n",
       "14       humanloop /  Curated list of awesome tools, demos, docs for...   \n",
       "\n",
       "   Contributors count    Language  \n",
       "0                 222  TypeScript  \n",
       "1                 225           C  \n",
       "2               9,671  TypeScript  \n",
       "3                  51  TypeScript  \n",
       "4                  35        Rust  \n",
       "5                  66          Go  \n",
       "6                 112      Python  \n",
       "7                 376        Rust  \n",
       "8                  40  JavaScript  \n",
       "9                 857         C++  \n",
       "10                464      Python  \n",
       "11              3,015  JavaScript  \n",
       "12                  9  JavaScript  \n",
       "13             10,307  TypeScript  \n",
       "14                 16  JavaScript  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making Dataframe\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df[\"Repository title\"]=Title\n",
    "df[\"Repository description\"]=Descr\n",
    "df[\"Contributors count\"]=Count\n",
    "df[\"Language\"]=Language\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f743fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12ecf4cc",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19d3d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\hp\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#Lets maximize web driver\n",
    "driver.maximize_window()\n",
    "\n",
    "#Opening the url\n",
    "\n",
    "driver.get(\"https:/www.billboard.com/\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f725213",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hot_100=driver.find_element(By.XPATH,\"//a[@class='c-link  lrv-a-unstyle-link lrv-u-background-color-brand-secondary-dark lrv-u-color-grey-lightest lrv-u-color-grey-lightest:hover lrv-u-width-100p lrv-u-text-align-center lrv-a-hover-effect lrv-u-background-color-grey-dark:hover a-font-accent-fancy lrv-u-font-size-20 u-padding-tb-15 u-letter-spacing-0112 lrv-a-icon-after a-icon-magazine lrv-u-justify-content-center lrv-u-align-items-center lrv-a-unstyle-link u-width-100p@tablet u-width-235@mobile-max lrv-u-margin-t-050@mobile-max u-background-color-white@mobile-max u-color-black@mobile-max lrv-u-border-a-1@mobile-max lrv-u-border-color-brand-accent-red u-line-height-1']\")\n",
    "Hot_100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afc06af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Song Name\n",
    "song=[]\n",
    "sng=driver.find_elements(By.XPATH, \"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet']\")\n",
    "sng1=driver.find_elements(By.XPATH,\"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "for i in sng:\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        song.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        song.append(\"-\")\n",
    "        \n",
    "for j in sng1:\n",
    "    try:\n",
    "        \n",
    "        song.append(j.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        song.append(\"-\")\n",
    "        \n",
    "len(song)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a0939898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Artist=[]\n",
    "art=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet']\")\n",
    "art1=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "\n",
    "for i in art:\n",
    "          \n",
    "    try:\n",
    "        \n",
    "        Artist.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Artist.append(\"-\")\n",
    "            \n",
    "for j in art1:\n",
    "    \n",
    "    try:\n",
    "        Artist.append(j.text)\n",
    "    except NoSuchElementException:\n",
    "        Artist.append(\"-\")\n",
    "len(Artist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eb57e35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rank=[]\n",
    "r=driver.find_elements(By.XPATH,\"//li[4][@class='o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max']\")\n",
    "\n",
    "for i in r:\n",
    "    \n",
    "    \n",
    "          \n",
    "    try:\n",
    "        \n",
    "        Rank.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Rank.append(\"-\")\n",
    "        \n",
    "len(Rank)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3f603df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WOB=[]\n",
    "\n",
    "w1=driver.find_elements(By.XPATH,\"//li[6][@class='o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max']\")\n",
    "\n",
    "for i in w1:\n",
    "    \n",
    "          \n",
    "    try:\n",
    "        \n",
    "        \n",
    "        WOB.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        WOB.append(\"-\")\n",
    "        \n",
    "len(WOB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a76335a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_rank=[]\n",
    "pr=driver.find_elements(By.XPATH,\"//li[5][@class='o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-hidden@mobile-max']\")\n",
    "\n",
    "for i in pr:\n",
    "    \n",
    "          \n",
    "    try:\n",
    "        \n",
    "        \n",
    "        peak_rank.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        peak_rank.append(\"-\")\n",
    "        \n",
    "len(peak_rank)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4706ef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mamking DataFrame\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df[\"Song name\"]=song\n",
    "df[\"Artist name\"]=Artist\n",
    "df[\"Last week rank\"]=Rank\n",
    "df[\"Peak rank\"]=peak_rank\n",
    "df[\"Weeks on board\"]=WOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "07942449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anti-Hero</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All I Want For Christmas Is You</td>\n",
       "      <td>Mariah Carey</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rockin' Around The Christmas Tree</td>\n",
       "      <td>Brenda Lee</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unholy</td>\n",
       "      <td>Sam Smith &amp; Kim Petras</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jingle Bell Rock</td>\n",
       "      <td>Bobby Helms</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Someday At Christmas</td>\n",
       "      <td>Lizzo</td>\n",
       "      <td>-</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Vigilante Shit</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>73</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Forget Me</td>\n",
       "      <td>Lewis Capaldi</td>\n",
       "      <td>-</td>\n",
       "      <td>95</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Going, Going, Gone</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Miss You</td>\n",
       "      <td>Oliver Tree &amp; Robin Schulz</td>\n",
       "      <td>91</td>\n",
       "      <td>84</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Song name                 Artist name  \\\n",
       "0                           Anti-Hero                Taylor Swift   \n",
       "1     All I Want For Christmas Is You                Mariah Carey   \n",
       "2   Rockin' Around The Christmas Tree                  Brenda Lee   \n",
       "3                              Unholy      Sam Smith & Kim Petras   \n",
       "4                    Jingle Bell Rock                 Bobby Helms   \n",
       "..                                ...                         ...   \n",
       "95               Someday At Christmas                       Lizzo   \n",
       "96                     Vigilante Shit                Taylor Swift   \n",
       "97                          Forget Me               Lewis Capaldi   \n",
       "98                 Going, Going, Gone                  Luke Combs   \n",
       "99                           Miss You  Oliver Tree & Robin Schulz   \n",
       "\n",
       "   Last week rank Peak rank Weeks on board  \n",
       "0               1         1              6  \n",
       "1               5         1             54  \n",
       "2               6         2             48  \n",
       "3               3         1             10  \n",
       "4               9         3             45  \n",
       "..            ...       ...            ...  \n",
       "95              -        96              1  \n",
       "96             73        10              6  \n",
       "97              -        95              6  \n",
       "98             98        98              3  \n",
       "99             91        84              6  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc79cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f01f7e9",
   "metadata": {},
   "source": [
    "# 7. Scrape the details of Data science recruiters from naukri.com. Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f7ad8445",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\hp\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#Lets maximize web driver\n",
    "driver.maximize_window()\n",
    "\n",
    "#Opening the url\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a9e83f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[1]/div/div/div/input\")\n",
    "DS.send_keys(\"Data Science\")\n",
    "\n",
    "Search_btn= driver.find_element(By.XPATH,\"//div[@class='qsbSubmit']\")\n",
    "Search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b71b1179",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unable to find the recruiters in naukari.com hence scrapping remaining details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c0e17d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Designation=[]\n",
    "d=driver.find_elements(By.XPATH,\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in d:      \n",
    "    try:  \n",
    "        Designation.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Designation.append(\"-\")\n",
    "len(Designation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3237d064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Company=[]\n",
    "c=driver.find_elements(By.XPATH,\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in c:      \n",
    "    try:  \n",
    "        Company.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Company.append(\"-\")\n",
    "len(Company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "06e8038a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Skill=[]\n",
    "s=driver.find_elements(By.XPATH,\"//ul[@class='tags has-description']\")\n",
    "for i in s:      \n",
    "    try:  \n",
    "        Skill.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Skill.append(\"-\")\n",
    "len(Skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f7a6d8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Location=[]\n",
    "l=driver.find_elements(By.XPATH,\"//span[@class='ellipsis fleft fs12 lh16 locWdth']\")\n",
    "for i in l:      \n",
    "    try:  \n",
    "        Location.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Location.append(\"-\")\n",
    "len(Location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "148b9e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skill</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analyst-Data Science</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>Data analysis\\ndata science\\npower bi\\nAdvance...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science- Data Scientist/Sr. Data Scientist</td>\n",
       "      <td>Jet2 Travel Technologies</td>\n",
       "      <td>Prototype\\ndata science\\nMySQL\\nOracle\\nBusine...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst / Data Science</td>\n",
       "      <td>Infoweb</td>\n",
       "      <td>Java\\nAdvanced Analytics\\nPython Development\\n...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analyst-Data Science</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>SAS\\ndata science\\nAnalytical\\nMachine learnin...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science - Engineering Manager</td>\n",
       "      <td>Paytm</td>\n",
       "      <td>Computer science\\nData analysis\\nMachine learn...</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Data Science</td>\n",
       "      <td>Bristlecone</td>\n",
       "      <td>Procurement\\nSupply chain\\nSAN\\nAutomation\\nIn...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sr. Manager - Data Science</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>Automation\\nFinance\\nArtificial Intelligence\\n...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Deputy National Lead - Payments - Data Science</td>\n",
       "      <td>BAJAJ FINSERVE</td>\n",
       "      <td>Automation\\nTeam management\\nMachine learning\\...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Science Engineer</td>\n",
       "      <td>Geeky Bee AI Pvt Ltd</td>\n",
       "      <td>machine learning\\nScikit-Learn\\nData Science\\n...</td>\n",
       "      <td>Pune(Wakad)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Manager / Senior Manager - Data Science</td>\n",
       "      <td>PYLON Management Consulting Private Limited</td>\n",
       "      <td>Data Science\\nText analytics\\nR\\nNLP\\nSAS\\nNeu...</td>\n",
       "      <td>Pune, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Manager-Data Science</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>Analytical skills\\nCustomer management\\nTechni...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lead Data Scientist - Data Sciences</td>\n",
       "      <td>GEP</td>\n",
       "      <td>Procurement\\nComputer vision\\nData analysis\\nO...</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Assistant Manager - Data Science, Need Immedia...</td>\n",
       "      <td>Citiustech</td>\n",
       "      <td>Data Science\\nNLP\\nMachine Learning\\nPython\\nA...</td>\n",
       "      <td>Hybrid - Pune, Gurgaon/Gurugram, Bangalore/Ben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>Ira Commerce</td>\n",
       "      <td>data science\\nSenior Analyst\\nAnalytical\\nProg...</td>\n",
       "      <td>Hyderabad/Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Manager, Data Science 1</td>\n",
       "      <td>Paypal</td>\n",
       "      <td>Product management\\nData analysis\\ndata scienc...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Manager, Data Science 1</td>\n",
       "      <td>Xoom</td>\n",
       "      <td>Product management\\nData analysis\\ndata scienc...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Analyst-Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Publishing\\nAnalytical\\nAnalytics\\nSQL\\nPython...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Technology Analyst / Data Science / Machine Le...</td>\n",
       "      <td>Infosys</td>\n",
       "      <td>Data Science\\nIT Skills\\nPython\\nTesting\\nQual...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>Publishing\\nArtificial Intelligence\\nConsultin...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Science Lead - Forecasting</td>\n",
       "      <td>Cargill</td>\n",
       "      <td>Data Science\\nData analysis\\nMachine learning\\...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Designation  \\\n",
       "0                                Analyst-Data Science   \n",
       "1     Data Science- Data Scientist/Sr. Data Scientist   \n",
       "2                         Data Analyst / Data Science   \n",
       "3                                Analyst-Data Science   \n",
       "4                  Data Science - Engineering Manager   \n",
       "5                       Data Scientist - Data Science   \n",
       "6                          Sr. Manager - Data Science   \n",
       "7      Deputy National Lead - Payments - Data Science   \n",
       "8                               Data Science Engineer   \n",
       "9             Manager / Senior Manager - Data Science   \n",
       "10                               Manager-Data Science   \n",
       "11                Lead Data Scientist - Data Sciences   \n",
       "12  Assistant Manager - Data Science, Need Immedia...   \n",
       "13                               Data Science Analyst   \n",
       "14                            Manager, Data Science 1   \n",
       "15                            Manager, Data Science 1   \n",
       "16                               Analyst-Data Science   \n",
       "17  Technology Analyst / Data Science / Machine Le...   \n",
       "18                        Senior Analyst-Data Science   \n",
       "19                    Data Science Lead - Forecasting   \n",
       "\n",
       "                                        Company  \\\n",
       "0                              AMERICAN EXPRESS   \n",
       "1                      Jet2 Travel Technologies   \n",
       "2                                       Infoweb   \n",
       "3                              AMERICAN EXPRESS   \n",
       "4                                         Paytm   \n",
       "5                                   Bristlecone   \n",
       "6                              AMERICAN EXPRESS   \n",
       "7                                BAJAJ FINSERVE   \n",
       "8                          Geeky Bee AI Pvt Ltd   \n",
       "9   PYLON Management Consulting Private Limited   \n",
       "10                             AMERICAN EXPRESS   \n",
       "11                                          GEP   \n",
       "12                                   Citiustech   \n",
       "13                                 Ira Commerce   \n",
       "14                                       Paypal   \n",
       "15                                         Xoom   \n",
       "16                                    Accenture   \n",
       "17                                      Infosys   \n",
       "18                                    Accenture   \n",
       "19                                      Cargill   \n",
       "\n",
       "                                                Skill  \\\n",
       "0   Data analysis\\ndata science\\npower bi\\nAdvance...   \n",
       "1   Prototype\\ndata science\\nMySQL\\nOracle\\nBusine...   \n",
       "2   Java\\nAdvanced Analytics\\nPython Development\\n...   \n",
       "3   SAS\\ndata science\\nAnalytical\\nMachine learnin...   \n",
       "4   Computer science\\nData analysis\\nMachine learn...   \n",
       "5   Procurement\\nSupply chain\\nSAN\\nAutomation\\nIn...   \n",
       "6   Automation\\nFinance\\nArtificial Intelligence\\n...   \n",
       "7   Automation\\nTeam management\\nMachine learning\\...   \n",
       "8   machine learning\\nScikit-Learn\\nData Science\\n...   \n",
       "9   Data Science\\nText analytics\\nR\\nNLP\\nSAS\\nNeu...   \n",
       "10  Analytical skills\\nCustomer management\\nTechni...   \n",
       "11  Procurement\\nComputer vision\\nData analysis\\nO...   \n",
       "12  Data Science\\nNLP\\nMachine Learning\\nPython\\nA...   \n",
       "13  data science\\nSenior Analyst\\nAnalytical\\nProg...   \n",
       "14  Product management\\nData analysis\\ndata scienc...   \n",
       "15  Product management\\nData analysis\\ndata scienc...   \n",
       "16  Publishing\\nAnalytical\\nAnalytics\\nSQL\\nPython...   \n",
       "17  Data Science\\nIT Skills\\nPython\\nTesting\\nQual...   \n",
       "18  Publishing\\nArtificial Intelligence\\nConsultin...   \n",
       "19  Data Science\\nData analysis\\nMachine learning\\...   \n",
       "\n",
       "                                             Location  \n",
       "0                                    Gurgaon/Gurugram  \n",
       "1                                                Pune  \n",
       "2                                                Pune  \n",
       "3                                    Gurgaon/Gurugram  \n",
       "4                      New Delhi, Bangalore/Bengaluru  \n",
       "5                                              Mumbai  \n",
       "6                                    Gurgaon/Gurugram  \n",
       "7                                                Pune  \n",
       "8                                         Pune(Wakad)  \n",
       "9         Pune, Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "10                                   Gurgaon/Gurugram  \n",
       "11                                             Remote  \n",
       "12  Hybrid - Pune, Gurgaon/Gurugram, Bangalore/Ben...  \n",
       "13                             Hyderabad/Secunderabad  \n",
       "14                                            Chennai  \n",
       "15                                            Chennai  \n",
       "16                                Bangalore/Bengaluru  \n",
       "17                                Bangalore/Bengaluru  \n",
       "18                                             Mumbai  \n",
       "19                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making DataFrame\n",
    "df=pd.DataFrame()\n",
    "df[\"Designation\"]=Designation\n",
    "df[\"Company\"]=Company\n",
    "df[\"Skill\"]=Skill\n",
    "df[\"Location\"]=Location\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8c8fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23a9e912",
   "metadata": {},
   "source": [
    "# 8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey- compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "503e1c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\hp\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#Lets maximize web driver\n",
    "driver.maximize_window()\n",
    "\n",
    "#Opening the url\n",
    "\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f19fa12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Book=[]\n",
    "book=driver.find_elements(By.XPATH,\"//td[2][@class='left']\")\n",
    "\n",
    "for i in book:      \n",
    "    try:  \n",
    "        Book.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Book.append(\"-\")\n",
    "len(Book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a4639e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Author=[]\n",
    "au=driver.find_elements(By.XPATH,\"//td[3][@class='left']\")\n",
    "\n",
    "for i in au:      \n",
    "    try:  \n",
    "        Author.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Author.append(\"-\")\n",
    "len(Author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3b6ab96b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VS=[]\n",
    "vs=driver.find_elements(By.XPATH,\"//td[4][@class='left']\")\n",
    "\n",
    "for i in vs:      \n",
    "    try:  \n",
    "        VS.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        VS.append(\"-\")\n",
    "len(VS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "909ea8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Publisher=[]\n",
    "ps=driver.find_elements(By.XPATH,\"//td[5][@class='left']\")\n",
    "\n",
    "for i in ps:      \n",
    "    try:  \n",
    "        Publisher.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Publisher.append(\"-\")\n",
    "len(Publisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1aee136f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Genre=[]\n",
    "gn=driver.find_elements(By.XPATH,\"//td[@class='last left']\")\n",
    "\n",
    "for i in gn:      \n",
    "    try:  \n",
    "        Genre.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Genre.append(\"-\")\n",
    "len(Genre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "69c06cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making DataFrame\n",
    "df=pd.DataFrame()\n",
    "df[\"Book Name\"]=Book\n",
    "df[\"Author Name\"]=Author\n",
    "\n",
    "df[\"Publisher\"]=Publisher\n",
    "df[\"Volume Sale\"]=VS\n",
    "df[\"Genre\"]=Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "921669f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Volume Sale</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>Random House</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>Random House</td>\n",
       "      <td>807,311</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>Orion</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "          Publisher Volume Sale                        Genre  \n",
       "0        Transworld   5,094,805  Crime, Thriller & Adventure  \n",
       "1        Bloomsbury   4,475,152           Children's Fiction  \n",
       "2        Bloomsbury   4,200,654           Children's Fiction  \n",
       "3        Bloomsbury   4,179,479           Children's Fiction  \n",
       "4      Random House   3,758,936              Romance & Sagas  \n",
       "..              ...         ...                          ...  \n",
       "95     Random House     807,311   General & Literary Fiction  \n",
       "96          Penguin     794,201        Food & Drink: General  \n",
       "97  Scholastic Ltd.     792,187          Young Adult Fiction  \n",
       "98            Orion     791,507           Biography: General  \n",
       "99          Penguin     791,095        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e45be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "103e12e1",
   "metadata": {},
   "source": [
    "# 9. Scrape the details most watched tv series of all time from imdb.com. Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "78fdd237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\hp\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#Lets maximize web driver\n",
    "driver.maximize_window()\n",
    "\n",
    "#Opening the url\n",
    "\n",
    "driver.get(\"https://www.imdb.com/list/ls095964455/\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "45e763bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name=[]\n",
    "name=driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']\")\n",
    "\n",
    "for i in name:      \n",
    "    try:  \n",
    "        Name.append(i.text.strip())\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Name.append(\"-\")\n",
    "len(Name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "86d8f489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Year=[]\n",
    "year=driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "for i in year:      \n",
    "    try:  \n",
    "        Year.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Year.append(\"-\")\n",
    "        \n",
    "len(Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "19ddc8a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Genre=[]\n",
    "\n",
    "gn=driver.find_elements(By.XPATH,\"//span[@class='genre']\")\n",
    "for i in gn:      \n",
    "    try:  \n",
    "        Genre.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Genre.append(\"-\")\n",
    "        \n",
    "len(Genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9f569c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Runtime=[]\n",
    "rn=driver.find_elements(By.XPATH,\"//span[@class='runtime']\")\n",
    "for i in rn:      \n",
    "    try:  \n",
    "        Runtime.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Runtime.append(\"-\")\n",
    "        \n",
    "len(Runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "55324cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rating=[]\n",
    "rt=driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']\")\n",
    "for i in rt:      \n",
    "    try:  \n",
    "        Rating.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Rating.append(\"-\")\n",
    "        \n",
    "len(Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a16dbf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Votes=[]\n",
    "vt=driver.find_elements(By.XPATH,\"//span[@name='nv']\")\n",
    "for i in vt:      \n",
    "    try:  \n",
    "        Votes.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Votes.append(\"-\")\n",
    "        \n",
    "len(Votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8b6ce036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAking DataFrame\n",
    "df=pd.DataFrame()\n",
    "df[\"Name\"]=Name\n",
    "df[\"Year span\"]=Year\n",
    "df[\"Genre\"]=Genre\n",
    "df[\"Run time\"]=Runtime\n",
    "df[\"Ratings\"]=Rating\n",
    "df[\"Votes\"]=Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6dde0182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Game of Thrones (2011–2019)</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,090,484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Stranger Things (2016– )</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,180,030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. The Walking Dead (2010–2022)</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>989,188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. 13 Reasons Why (2017–2020)</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>292,916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. The 100 (2014–2020)</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>252,054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96. Reign (2013–2017)</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>50,192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97. A Series of Unfortunate Events (2017–2019)</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>61,479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98. Criminal Minds (2005– )</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>198,403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99. Scream: The TV Series (2015–2019)</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100. The Haunting of Hill House (2018)</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>245,306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Name    Year span  \\\n",
       "0                   1. Game of Thrones (2011–2019)  (2011–2019)   \n",
       "1                      2. Stranger Things (2016– )     (2016– )   \n",
       "2                  3. The Walking Dead (2010–2022)  (2010–2022)   \n",
       "3                    4. 13 Reasons Why (2017–2020)  (2017–2020)   \n",
       "4                           5. The 100 (2014–2020)  (2014–2020)   \n",
       "..                                             ...          ...   \n",
       "95                           96. Reign (2013–2017)  (2013–2017)   \n",
       "96  97. A Series of Unfortunate Events (2017–2019)  (2017–2019)   \n",
       "97                     98. Criminal Minds (2005– )     (2005– )   \n",
       "98           99. Scream: The TV Series (2015–2019)  (2015–2019)   \n",
       "99          100. The Haunting of Hill House (2018)       (2018)   \n",
       "\n",
       "                       Genre Run time Ratings      Votes  \n",
       "0   Action, Adventure, Drama   57 min     9.2  2,090,484  \n",
       "1     Drama, Fantasy, Horror   51 min     8.7  1,180,030  \n",
       "2    Drama, Horror, Thriller   44 min     8.1    989,188  \n",
       "3   Drama, Mystery, Thriller   60 min     7.5    292,916  \n",
       "4     Drama, Mystery, Sci-Fi   43 min     7.6    252,054  \n",
       "..                       ...      ...     ...        ...  \n",
       "95                     Drama   42 min     7.4     50,192  \n",
       "96  Adventure, Comedy, Drama   50 min     7.8     61,479  \n",
       "97     Crime, Drama, Mystery   42 min     8.1    198,403  \n",
       "98      Comedy, Crime, Drama   45 min     7.1     41,584  \n",
       "99    Drama, Horror, Mystery  572 min     8.6    245,306  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1241e5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4b6cef3",
   "metadata": {},
   "source": [
    "# 10. Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "35388d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets first connect web driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\hp\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "\n",
    "#Lets maximize web driver\n",
    "driver.maximize_window()\n",
    "\n",
    "#Opening the url\n",
    "\n",
    "driver.get(\"https://archive.ics.uci.edu/\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "44b27d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sd=driver.find_element(By.XPATH,\"//span[@class='whitetext']\")\n",
    "sd.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "265f363c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name=[]\n",
    "n=driver.find_elements(By.XPATH,\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[*]/td[1]/table/tbody/tr/td[2]/p/b/a\")\n",
    "for i in n:\n",
    "    \n",
    "    try:  \n",
    "        Name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Name.append(\"-\")\n",
    "        \n",
    "len(Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "198d416f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_Type=[]\n",
    "d=driver.find_elements(By.XPATH,\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr[*]/td[2]/p\")\n",
    "for i in d[0:622]:\n",
    "    \n",
    "    try:  \n",
    "        Data_Type.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Data_Type.append(\"-\")\n",
    "        \n",
    "len(Data_Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "859b426c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Task=[]\n",
    "t=driver.find_elements(By.XPATH,\"//td[3]/p[@class='normal']\")\n",
    "for i in t[0:622]:\n",
    "    \n",
    "    try:  \n",
    "        Task.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        Task.append(\"-\")\n",
    "        \n",
    "len(Task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ab61a486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Attribute Type\n",
    "AT=[]\n",
    "at=driver.find_elements(By.XPATH,\"//td[4]/p[@class='normal']\")\n",
    "for i in at:\n",
    "    \n",
    "    try:  \n",
    "        AT.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        AT.append(\"-\")\n",
    "        \n",
    "len(AT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6f8c521c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No. of instances\n",
    "NI=[]\n",
    "ni=driver.find_elements(By.XPATH,\"//td[5]/p[@class='normal']\")\n",
    "for i in ni:\n",
    "    \n",
    "    try:  \n",
    "        NI.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        NI.append(\"-\")\n",
    "        \n",
    "len(NI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c586766d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of Attributes\n",
    "NA=[]\n",
    "na=driver.find_elements(By.XPATH,\"//td[6]/p[@class='normal']\")\n",
    "for i in na:\n",
    "    \n",
    "    try:  \n",
    "        NA.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        NA.append(\"-\")\n",
    "        \n",
    "len(NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "80c79480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year=[]\n",
    "y=driver.find_elements(By.XPATH,\"//td[7]/p[@class='normal']\")\n",
    "for i in y:\n",
    "    \n",
    "    try:  \n",
    "        year.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "                \n",
    "        year.append(\"-\")\n",
    "        \n",
    "len(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f8bb187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making Dataframe\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df[\"Dataset Name\"]=Name\n",
    "df[\"Data Type\"]=Data_Type\n",
    "df[\"Task\"]=Task\n",
    "df[\"Attribute Type\"]=AT\n",
    "df[\"No. of Instances\"]=NI\n",
    "df[\"No. of Attribute\"]=NA\n",
    "df[\"Year\"]=year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cce14d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No. of Instances</th>\n",
       "      <th>No. of Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Data Types</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset Name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data Type                  Task  \\\n",
       "0                    Data Types       Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                 Multivariate   Recommender-Systems    \n",
       "4                                     Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619               Multivariate        Classification    \n",
       "620                                   Classification    \n",
       "621  Multivariate, Time-Series            Regression    \n",
       "\n",
       "                  Attribute Type No. of Instances No. of Attribute   Year  \n",
       "0    Categorical, Integer, Real             4177                8   1995   \n",
       "1          Categorical, Integer            48842               14   1996   \n",
       "2    Categorical, Integer, Real              798               38          \n",
       "3                   Categorical            37711              294   1998   \n",
       "4    Categorical, Integer, Real              452              279   1998   \n",
       "..                           ...              ...              ...    ...  \n",
       "617               Integer, Real            75840              525   2020   \n",
       "618               Integer, Real              400               50   2020   \n",
       "619                                         1014                7   2020   \n",
       "620                        Real            10129               16   2021   \n",
       "621                        Real             4000                2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d03739c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
